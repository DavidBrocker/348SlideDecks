---
title: "One-Sample T-Test"
subtitle: "Lecture 9"
author: "Dave Brocker"
footer: "PSY 348 - Statistics for Psychology"
institute: "Farmingdale State College"
format: 
  revealjs:
    theme: custom.scss
    incremental: true   
    touch: true
    chalkboard: true
    lightbox: true
    code-fold: true
    width: 1600
    height: 900
---

## Recap

### How Did We Get Here!

-   We began the semester by discussing how to define and measure psychological and abstract concepts.

-   We explored different types of variables and scales of measurement, learning how data can be categorized or quantified.

-   We used the normal distribution to examine variability and to understand how scores can be assigned probability values using standardized (z) scores.

-   Through sampling theory, we saw how many possible samples create a distribution of sample means, centered around the true population mean.

-   If we can estimate the probability that a sample mean came from a particular distribution, can we also estimate whether it came from the null or the alternative hypothesis?

## From Probability to Decision-Making
-   Once we know how likely a sample mean is to occur, we can begin to make decisions about what that likelihood means.

-   We introduced two competing ideas:

    -   Null hypothesis ($H_0$): No real difference or effect.
    -   Alternative hypothesis ($H_1$): A true difference or effect exists.

-   Because samples vary, we can never be 100% certain—only confident to a degree.

## Errors in Estimation
### Type I and II Error

-   That degree of confidence is defined by α (alpha), our threshold for error when rejecting $H_0$.

-   $\beta$ (beta) represents the probability of missing a real effect (failing to reject $H_0$ when $H_1$ is true).
-   These lead to two types of decision errors:
      
    -   Type I error ($\alpha$): Finding a difference that isn’t really there. (False Positive)
    -   Type II error ($\beta$): Missing a difference that actually exists. (False Negative)

## The Truth Table

```{r}
library(gt)

# Create the table data
error_table <- data.frame(
  "Decision" = c("$$\\text{Reject }H_0$$", "$$\\text{Fail to Reject } H_0$$"),
  "null_true" = c("$$\\text{Type I Error }(\\alpha)$$", "$$\\text{Correct Decision}\\\\1-\\alpha$$"),
  "null_false" = c("$$\\text{Correct Decision}\\\\1-\\beta$$", "$$\\text{Type II Error } (\\beta)$$")
)

# Build the gt table
error_table %>%
  gt(rowname_col = "Decision") %>%
  tab_header(
    title = md("**Decision Outcomes in Hypothesis Testing**")
  ) %>%
  cols_label(
    null_true = md("$$H_0\\text{ True}$$"),
    null_false = md("$$H_0\\text{ False}$$")
  ) |> 
  fmt_markdown(columns = everything(),rows = everything()) |> 
  tab_style(
    style = cell_fill(color = "orange", alpha = .4),
    locations = 
      list(
        cells_body(columns = 2,rows = 1),
        cells_body(columns = 3, rows = 2)
      )
  ) |> 
  tab_options(
    table.font.size = 25,
    table.width = pct(70)
  )
```

## R

```{r}
library(dplyr)
library(ggplot2)
set.seed(101)
df_sampling <- tibble(
  value = c(rnorm(500, mean = 4.4, sd = 1.2),
            rnorm(500, mean = 8.8, sd = 1.2)),
  group = rep(c("FSC","JJJSMU"), each = 500)
)

df_sampling |> 
  ggplot(aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = c(4.4,8.8),lty = "dashed") +
  labs(title = "Two Overlapping Distributions as Population Distributions",
       x = "\nValue", y = "Density\n") +
  theme_minimal()
```

## Before We Compare Means…

-   Every statistical test is about making a decision:

    -   Is our result likely due to chance, or does it reflect a real difference?

-   Two key players in this decision:

    -   α (alpha): our threshold for how much error we’ll tolerate (Type I Error)

    -   β (beta): the risk of missing a real effect (Type II Error)

-   Balancing α and β helps us manage:

    -   False alarms (rejecting a true null)
    -   Missed detections (failing to reject a false null)

## Why Compare Means?

-   We often want to test whether a sample mean differs from a known population mean.
-   The one-sample t-test helps determine if the sample mean is significantly different from the hypothesized population mean.
-   Example scenarios:
    -   Does the average exam score in a class differ from a national average of 75?
    -   Do people’s reaction times differ from a published standard of 250ms?
    -   Tests against the midpoint of a scale

## The t-test

### Three Types - Three Cases

:::::: columns
::: {.column width="33%"}
-   One-Sample T-Test
    -   $t=\frac{\bar{x}-\mu}{\sigma} |\frac{\bar{x}}{s/\sqrt(n)}$
:::

::: {.column width="33%"}
-   Paired-Samples T Test
    -   $t=\frac{\bar{D}}{\sigma_{\bar{D}}}|\frac{\bar{D}}{s_{\bar{D}}/\sqrt(n)}$
:::

::: {.column width="33%"}
-   Independent-Samples T Test
    -   $t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$
:::
::::::

-   We use the sample standard deviation ($s$) to estimate the standard error ($s/\sqrt{n}$) since population σ is typically unknown.
-   In all cases, variation in statistical significance factors in degrees of freedom (df)
    -   Accounts for variability in sampling

## The t-distribution

```{r}
library(dplyr)
library(ggplot2)

library(tidyverse)

df <- tibble(
  t.values = seq(-4, 4, .1),
  df3 = dt(t.values, 3),
  df10 = dt(t.values, 10),
  df30 = dt(t.values, 30),
  df80 = dt(t.values, 80),
  normal = dnorm(t.values)
) %>%
  pivot_longer(cols = -t.values, names_to = "distribution", values_to = "density")

ggplot(df, aes(x = t.values, y = density, color = distribution, linetype = distribution)) +
  geom_line(size = 1.2) +
  scale_color_manual(values = c(
    "df3" = "#E69F00",
    "df10" = "#56B4E9",
    "df30" = "#009E73",
    "df80" = "#0072B2",
    "normal" = "black"
  )) +
  labs(
    title = "t-Distributions with Increasing Degrees of Freedom",
    x = "\nt-value",
    y = "Probability Density\n"
  ) +
  theme_minimal(base_size = 20) +
  theme(legend.position = "top")
```

## Assumptions of the One-Sample t-Test

1.  The data are continuous (interval or ratio scale).
2.  The sample is randomly selected.
3.  The data are normally distributed (or the sample size is large enough for the Central Limit Theorem to apply).

## The One-Sample t-Test Formula

The test statistic is calculated as:

::: callout-tip
## One Sample T-Test

$\large{t = \frac{\color{red}{\bar{x}}-\color{blue}{\mu}}{\color{orange}{\sigma}}}$
:::

Where:

-   $\color{red}{\bar{x}}$ = sample mean

-   $\color{blue}{\mu}$ = population mean (null hypothesis value)

-   $\color{orange}{\sigma}{\text{ or }}SE$

    -   $s$ = sample standard deviation

    -   $\sqrt{n}$ = sample size

## Hypothesis Testing Steps

1.  Set Hypotheses
    1.  Define both the Null and Alternative
2.  Collect Sample Data:
    1.  Use the appropriate sampling method and collect needed data\*
3.  Compute the t-Statistic:
    1.  Conduct the correct t-test
4.  Compare to Critical Value:
    1.  Use the t-statistic, sample-size, and alpha level to determine statistical significance.

## Hypothesis Testing Steps

### Manual

1.  Set Hypotheses:
    -   $H_0$: The average exam score is 75 ($\mu = 75$).
    -   $H_A$: The average exam score is not 75 ($\mu \neq 75$).
2.  Collect Sample Data:
    -   Sample size: $n = 20$
    -   Sample mean: $\bar{x} = 78$
    -   Sample standard deviation: $s = 5$

## Hypothesis Testing Steps

### Manual

3.  Compute the t-Statistic:

    -   $t = \frac{78 - 75}{\frac{5}{\sqrt{20}}} = \frac{3}{1.118} = 2.68$

4.  Compare to Critical Value:

    -   Using a $\alpha = 0.05$ level and df = 19, critical
    -   $t_{critical} = \pm 2.093$.
    -   Since $2.68 > 2.093$, we reject $H_0$.

## Hypothesis Testing Steps

### Programmatic

```{r}
#| echo: true

library(dplyr)
library(broom)
library(gt)

# Using Functions
n = 20
m = 78
mu = 75
s = 5
dat <- rnorm(n,m,s) |> round(0)
t.test(dat,mu = mu) |> 
  tidy() |> 
  rename(
    M = estimate,
    t = statistic,
    df = parameter,
    p = p.value
  ) |>
  gt(rowname_col = "method") |> 
  fmt_auto() |> 
  opt_row_striping()

# Manually
(m-mu)/(5/sqrt(n))
```

## Reporting Results

### APA-style:

> A one-sample t-test was conducted to compare exam scores to the national average of `75`. Results showed a significant difference, `t(19) = 2.68, p < .05`, indicating that students scored significantly higher than the national average.

-   What kind of test?
-   What is being compared?
-   Is it significant?
-   What are the test results?

## Reporting Results

### APA-style:

> A [one-sample t-test]{style="background-color: orange;"} was conducted to [compare exam scores to the national average]{style="background-color:orange;"} of `75`. Results showed a [significant difference]{style="background-color:orange;"}, `t(19) = 2.68, p < .05`, indicating that students scored significantly higher than the national average.

-   What kind of test?
-   What is being compared?
-   Is it significant?
-   What are the test results?

## Interpreting Results

### Sample Summary Table

-   A significant result ($p < .05$) suggests that the sample mean is different from the population mean.
-   A non-significant result ($p > .05$) means we fail to reject $H_0$ (no evidence of a difference).

```{r}
t.test(dat,mu = mu) |> 
  tidy() |> 
  rename(
    M = estimate,
    t = statistic,
    df = parameter,
    p = p.value
    ) |>
  gt(rowname_col = "method") |> 
  fmt_auto() |> 
  opt_row_striping() |> 
  tab_options(table.font.size = 20)
```

## Visualizing Data

::::: columns
::: {.column width="50%"}
```{r}
library(ggplot2)
data <- data.frame(Scores = c(72, 74, 76, 78, 80, 81, 77, 79, 78, 76,
                             80, 82, 74, 75, 78, 77, 76, 79, 80, 78))
ggplot(data, aes(y = Scores)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_hline(yintercept = 78, lty = "dashed", color = "red") +
  theme_minimal(base_size = 20) +
  ggtitle("Exam Scores Distribution") + 
  annotate("text", x = .5, y = median(data$Scores), 
           label = "Median", hjust = 0, color = "blue") +

  # Annotate IQR (Box)
  annotate("text", x = 1.2, y = quantile(data$Scores, 3/4), 
           label = "Q3 (75th percentile)", hjust = 0, color = "red") +
  annotate("text", x = 1.2, y = quantile(data$Scores, 1/4), 
           label = "Q1 (25th percentile)", hjust = 0, color = "red") +
  
  # Annotate Whiskers
  annotate("text", x = 0.8, y = max(data$Scores), 
           label = "Max (Upper Whisker)", hjust = 1, color = "black") +
  annotate("text", x = 0.8, y = min(data$Scores), 
           label = "Min (Lower Whisker)", hjust = 1, color = "black")
```
:::

::: {.column width="50%"}
```{r}

data <- 
  tibble(
    scores = rnorm(40,78,3)
  )

ggplot(data, aes(x = "", y = scores)) +
  geom_violin(color = "black") +
  geom_hline(yintercept = 78, lty = "dashed", color = "red") +
  geom_jitter(height = 0,width = .01) +
  theme_minimal(base_size = 20) +
  labs(
    title = "Exam Scores Distribution"
    ) 
```
:::
:::::

## Exam Scores vs. National Average

### Programmatic

> A professor wants to test if students in their class scored differently from the national average of `75` on an exam. A sample of `25` students has a mean score of `78` with a standard deviation of `10`.

```{r}
#| echo: true

# For Reproduceability
set.seed(131)

# Generate a random dataset with mean of 78, sd of 10
x <- rnorm(25,78,10)

t.test(
  x,
  # Specify that the mean to test against is 75
  mu = 75
  )

```

## Exam Scores vs. National Average

### Manual

> A professor wants to test if students in their class scored differently from the national average of `75` on an exam. A sample of `25` students has a mean score of `78` with a standard deviation of `10`.

-   Hypotheses

    -   Null Hypothesis ($H_0$): ( $\mu = 75$ ) (no difference)

    -   Alternative Hypothesis ($H_A$): ( $\mu \neq 75$ ) (scores differ)

## Exam Scores vs. National Average

### Manual

-   Using the one-sample t-test formula:

    -   $t = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} |t = \frac{78 - 75}{\frac{10}{\sqrt{25}}} = \frac{3}{2} = 1.5$

-   For df = 24 (25-1), the critical value at α = .05 (two-tailed) is ±2.064.

-   Since 1.5 \< 2.064, we fail to reject $H_0$.

## APA Reporting

> A one-sample t-test was conducted to determine whether students’ exam scores differed from the national average (M = 75). Results were not statistically significant, ( t(24) = 1.5, p \> .05 ), indicating that students performed similarly to the national average.

## Daily Coffee Consumption

> A coffee company claims that people drink an average of `3 cups` of coffee per day. A researcher samples `16 individuals`, finding a mean of `2.5 cups` and a standard deviation of `1 cup`.

-   Hypotheses

    -   Null Hypothesis ($H_0$): $\mu = 3$
    -   Alternative Hypothesis ($H_A$): $\mu < 3$ (people drink less)

## Daily Coffee Consumption

### Manual

> A coffee company claims that people drink an average of `3 cups` of coffee per day. A researcher samples `16 individuals`, finding a mean of `2.5 cups` and a standard deviation of `1 cup`.

-   Calculation

    -   $t = \frac{2.5 - 3}{1 / \sqrt{16}} = \frac{-0.5}{0.25} = -2.0$

-   For df = 15 (16-1), the critical t-value for a one-tailed test at α = .05 is -1.753.

-   Since -2.0 \< -1.753, we reject $H_0$.

## Daily Coffee Consumption

### Programmatic

> A coffee company claims that people drink an average of `3 cups` of coffee per day. A researcher samples `16 individuals`, finding a mean of `2.5 cups` and a standard deviation of `1 cup`.

```{r}
#| echo: true

# For Reproduceability
set.seed(131)

# Generate a random dataset with mean of 78, sd of 10
x <- rnorm(16,2.5,1)

t.test(
  x,
  # Specify that the mean to test against is 75
  mu = 3
  )

```

## APA Reporting

> A one-sample t-test was conducted to test whether daily coffee consumption was lower than the reported average of `3 cups`. Results showed a significant difference, `t(15)=-2.0,p< .05`, suggesting that people consume significantly fewer cups of coffee per day than reported.

## Sleep Duration Among College Students

> A health researcher believes college students sleep less than `7 hours` per night. A sample of `30 students` reports a mean of `6.5` hours with a standard deviation of `1.2` hours.

-   Hypotheses

    -   Null Hypothesis $H_0$: $\mu = 7$
    -   Alternative Hypothesis $H_1$: $\mu < 7$

## Sleep Duration Among College Students

### Manual

> A health researcher believes college students sleep less than `7 hours` per night. A sample of `30 students` reports a mean of `6.5` hours with a standard deviation of `1.2` hours.

-   Calculation

    -   $t = \frac{6.5 - 7}{1.2 / \sqrt{30}} = \frac{-0.5}{0.219} = -2.28$

-   For df = `29`, the critical t-value for a one-tailed test at α = .05 is `-1.699`.

-   Since `-2.28` \< -1.699, we reject (H_0).

## Sleep Duration Among College Students

### Programmatic

> A health researcher believes college students sleep less than `7 hours` per night. A sample of `30 students` reports a mean of `6.5` hours with a standard deviation of `1.2` hours.

```{r}
#| echo: true

# For Reproduceability
set.seed(728)

# Generate a random dataset with mean of 78, sd of 10
x <- rnorm(30,6.5,1.2) |> round(0)

t.test(
  x,
  # Specify that the mean to test against is 75
  mu = 7
  )
```

## APA Reporting

> A one-sample t-test was conducted to test whether college students sleep fewer than 7 hours per night. Results were statistically significant, t(29) = -2.28, p \< .05, indicating that students get significantly less sleep than the recommended amount.



```{r}

mn <- 
  replicate(100,
            {
            x  = rnorm(30,6.5,1.2) |> round(0)
            t.test(x, mu = 7)$estimate
            }
  )

t.test(
  x,
  # Specify that the mean to test against is 75
  mu = 7
  )



```