{
  "hash": "45db482ffce8ce3fbd552dbb45c151d7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis Testing, Pt 2\"\nsubtitle: \"Lecture 10\"\nauthor: \"Dave Brocker\"\ninstitute: \"Farmingdale State College\"\nformat: \n  revealjs:\n    theme: custom.scss\n    incremental: true   \n    touch: true\n    scrollable: true\n    chalkboard: true\n    lightbox: true\nfilters:\n  - webr\n---\n\n\n\n\n## Review\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n\n## Review\n\n### Sampling Theory\n\n::: fragment\n**Sample Mean:**\n:::\n\n::: fragment\nIf we took infinite samples of a population, the mean of each sample taken would be a Sample Mean -- like how each student collect 500 responses about TV show ratings and took the average of those 500 responses.\n:::\n\n::: fragment\n**Sampling Distribution:**\n:::\n\n::: fragment\nWhat we get if we put all the sample means together; we assume it's a normal distribution.\n:::\n\n## Sampling theory\n\nEach value in this distribution represents the average of 1 sample, a Sample Mean.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Sampling theory\n\n-   There are about 10,000 students at Farmingdale State College.\n\n-   Each of the 25 of us recruits a sample of 400 students.\n\n-   We ask every single FSC student to rate their sense of belonging on FSC campus on a scale of 1 (*I don't belong at all*) to 10 (*I belong completely*).\n\n-   We each calculate the average response from our own sample of 400.\n\n## Sampling Theory\n\n### Just Making Sure...\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n\n## P-Values\n\n### Yeah Can I Get Uhhhhh\n\n> Professor Brocker gives `100` students caffeinated coffee and another `100` students decaf. He then has them complete a stats exam.\n\n-   IV:\n\n-   DV:\n\n-   N =\n\n## P-Values\n\n### Yeah Can I Get Uhhhhh\n\n> Professor Brocker gives `100` students caffeinated coffee and another `100` students decaf. He then has them complete a stats exam.\n\n-   IV: Coffee Consumption (Coffee or No Coffee)\n\n-   DV: Exam Scores\n\n-   N = 200\n\n## P-Values\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## P-Values\n\nThe p-value tells us if the mean of the *experimental group* is far enough away from the *control group* mean that we can be confidence it belongs to a theoretical non-null distribution.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n\n## P-values and confidence intervals\n\n### Finding in terms of the null hypothesis\n\nIf there is a significant difference between the groups, p will be smaller than `0.05`.\n\n-   If p \\< (less than) `0.05`, the difference is **significant**, we *Reject* $H_0$.\n\n-   If p \\> (greater than) `0.05`, the difference is NOT **significant**, we *Fail to Reject* $H_0$.\n\n## Error ($\\beta$)\n\nHow often are we okay with making a mistake?\n\n::::: columns\n::: {.column width=\"50%\"}\nType 1:\n\n-   Reality: There is NO difference between the groups.\n\n-   Conclusion: There is a difference between the groups.\n:::\n\n::: {.column width=\"50%\"}\nType 2:\n\n-   Reality: There is a difference between the groups.\n\n-   Conclusion: There is NO difference between the groups.\n:::\n:::::\n\n## Types of Errors\n\n### Visual Aid\n\n::::: columns\n::: {.column width=\"50%\"}\n![](images/clipboard-2057166815.png){width=\"368\"}\n:::\n\n::: {.column width=\"50%\"}\n![](images/clipboard-63089270.png){width=\"300\"}\n:::\n:::::\n\n## Error\n\nHow often are we okay with making a mistake?\n\n-   It's better to make a Type 2 Error than a Type 1.\n    -   Type 1 kills people\n    -   Type 2 kills careers\n-   We want to minimize the chance of committing a Type 1 Error.\n\n## Error & Alpha\n\nWe accept a `5%` chance of committing a Type 1 Error.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n-   We set alpha ($\\alpha$) to `5%` or `0.05`\n\n## Error & Alpha\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n## Error & Alpha\n\n::: fragment\n![](images/clipboard-3692632542.png){width=\"629\"}\n:::\n\n## Significance\n\n::: fragment\n![](images/clipboard-1570428696.png){width=\"632\"}\n:::\n\n## Beta\n\n-   We set alpha at `5%` `(0.05)`, meaning we are okay with making a Type 1 Error (*false positive*) `5%` of the time.\n\n-   As a result, beta gets set at `16%`, meaning we have a 16% chance of committing Type 2 Error (*false negative*).\n\n## Alpha and Beta\n\n### Example\n\n![](images/clipboard-2847025632.png){width=\"350\"}\n\n## Error and Alpha and Beta\n\n-   Alpha ($\\alpha$) = probability of committing Type 1 Error\n\n-   Beta ($\\beta$)= probability of committing Type 2 Error\n\n## Error and Alpha and Beta\n\n+----------------------+-----------------------------+--------------------+\n|                      | $H_0$ True                  | $H_0$ False        |\n+======================+=============================+====================+\n| Fail to Reject $H_0$ | Correct Decision $1-\\alpha$ | Incorrect Decision |\n|                      |                             |                    |\n|                      |                             | Type II Error      |\n|                      |                             |                    |\n|                      |                             | $\\beta$            |\n+----------------------+-----------------------------+--------------------+\n| Reject $H_0$         | Incorrect Decision          | Correct Decision   |\n|                      |                             |                    |\n|                      | Type I Error                | $1-\\beta$          |\n|                      |                             |                    |\n|                      | $\\alpha$                    |                    |\n+----------------------+-----------------------------+--------------------+\n\n## Error and Alpha and Beta\n\n## Power & Effect Size\n\n## Sampling theory\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Null Hypothesis: $H_0$\n\nStates that nothing will happen while also naming of the variables (independent and dependent).\n\n-   The Null Hypothesis is written as $H_0$\n\n## Alternative hypothesis: $H_1|H_A$\n\nA **testable** prediction of what will happen in our experiment that names of the variables (independent and dependent) and clearly contrasts the groups.\n\n-   The Alternative Hypothesis is written as $H_1$\n\n## Hypothesis testing\n\n-   Null Hypothesis ($H_0$): These is **no** difference in the DV between the IV groups.\n\n-   Alternative Hypothesis ($H_1$): The experimental group is **significantly different** from the control group on the DV.\n\n## Hypothesis testing\n\n![](images/clipboard-1494090978.png){width=\"481\"}\n\n## P-values and confidence intervals\n\nIf there is a significant difference between the groups, p will be smaller than `0.05`.\n\n-   If p = .032...\n\n-   If p = .045...\n\n-   If p = .050...\n\n## Findings in terms of the null hypothesis\n\n-   If p \\< (less than) `0.05`, the difference is significant, we Reject $H_0$.\n\n-   If p \\> (greater than) `0.05`, the difference is NOT significant, we Fail to Reject $H_0$.\n\n## Alpha & beta\n\n![](images/clipboard-421457594.png){width=\"637\"}\n\n## Alpha & beta\n\n### $\\alpha$ and $\\beta$\n\n::: fragment\nAlpha: The probability of committing a Type 1 Error.\n\n-   We set $\\alpha$ to `0.05`\n:::\n\n::: fragment\nBeta: The probability of committing a Type 2 Error.\n\n-   When $\\alpha$ = `0.05`, the resulting $\\beta$ = `0.16`\n:::\n\n## Alpha & beta\n\n![](images/clipboard-421457594.png)\n\n## Types of Errors\n\n::::: columns\n::: {.column width=\"50%\"}\n### Type 1 Error\n\n-   **Reality**: There is NO difference between the groups.\n\n-   **Conclusion**: There is a difference between the groups.\n:::\n\n::: {.column width=\"50%\"}\n### Type 2 Error\n\n-   **Reality**: There is a difference between the groups.\n\n-   **Conclusion**: There is NO difference between the groups.\n:::\n:::::\n\n## Alpha and Beta and Power\n\n![](images/Screenshot%202024-10-07%20at%208.30.29%20AM.png){width=\"368\"}\n\n## Alpha & beta & power\n\n![](images/Screenshot%202024-10-07%20at%208.30.29%20AM.png){width=\"368\"}\n\n## Alpha & beta & power\n\n![](images/Screenshot%202024-10-07%20at%208.30.29%20AM.png){width=\"368\"}\n\n## Alpha & Beta & Power\n\n![](images/clipboard-421457594.png){width=\"317\"}\n\n## Alpha & beta & Power\n\n::: fragment\n**Alpha**: The probability of committing a Type 1 Error.\n:::\n\n-   We set $\\alpha$ to `0.05`\n\n::: fragment\n**Beta**: The probability of committing a Type 2 Error.\n:::\n\n-   When $\\alpha$ = `0.05`, the resulting $\\beta$ = `0.16`\n\n::: fragment\n**Power**: Ability of the researcher to accurately detect a difference between groups\n:::\n\n-   If $\\alpha$ = `0.05`, $\\beta$ = `0.16`, and the resulting power = `0.84`\n\n## Alpha & Beta & Power\n\n### Power\n\nPower refers to the ability of the researcher to accurately detect a difference between groups.\n\n-   When we assume a normal distribution, we assume power will be about `0.84` or `84%`.\n\n-   Power is dependent on Effect Size.\n\n## Effect Size\n\nEffect size in statistics refers to the [**strength of the relationship**]{.underline} between two variables in a population.\n\n-   Cohen's $d$\n-   Coefficient of Determination $R2$\n-   Omega Hat Squared \\| Eta Hat Squared\n    -   $\\hat{\\omega}^2$\n    -   $\\hat{\\eta}$\n\n## Effect Size Example\n\n> Does caffeine decrease the amount of time it takes to solve a puzzle?\n\n::::: columns\n::: {.column width=\"50%\"}\n![](images/clipboard-2323188496.png){width=\"212\"}\n:::\n\n::: {.column width=\"50%\"}\n![](images/clipboard-4121036724.png){width=\"249\"}\n:::\n:::::\n\n## Effect Size Example\n\n> Does caffeine decrease the amount of time it takes to solve a puzzle?\n\n-   IV:\n\n::: fragment\nCaffeine versus no caffeine\n:::\n\n-   DV:\n\n::: fragment\nTask speed\n:::\n\n## Effect Size Example\n\n> Does caffeine decrease the amount of time it takes to solve a puzzle?\n\n-   Effect Size:\n\n::: fragment\nStrength of the relationships between caffeine and task speed\n:::\n\n-   How much does caffeine actually impact task speed?\n\n## Effect size Example\n\n> Does caffeine decrease the amount of time it takes to solve a puzzle?\n\n::::: columns\n::: {.column width=\"50%\"}\n![](images/clipboard-2323188496.png){width=\"299\"}\n:::\n\n::: {.column width=\"50%\"}\n![](images/clipboard-4204953737.png){width=\"299\"}\n:::\n:::::\n\n## Effect size\n\nThe [**strength of the relationship**]{.underline} between two variables in a population.\n\nEffect size tells us how much one variable *actually* impacts the other.\n\n::::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec9_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::::\n\n```         \n```\n\n## Effect size:\n\n### Cohen's d\n\nEffect size in statistics refers to the [**strength of the relationship**]{.underline} between two variables in a population.\n\nCohen's d gives us a standardized measure of effect size:\n\n-   $d < 0.3$ is weak\n\n-   $0.3 < d > 0.5$ is moderate\n\n-   $d > 0.7$ is strong\n\n## Cohen's d\n\n### Formula\n\n-   Cohen's d is calculated by subtracting the mean of the experimental group from the mean of the control group and dividing it by the \"pooled standard deviation.\"\n\n-   The pooled standard deviation refers to the average SD across the 2 groups.\n\n::: fragment\n$d = \\frac{M_2-M_1}{\\sqrt{\\frac{SD_1^2\\ +\\ SD_2^2}{2}}}$\n:::\n\n## Cohen's d\n\n### Understanding the Terms\n\n::: fragment\n$d = \\frac{M_2-M_1}{\\sqrt{\\frac{SD_1^2\\ +\\ SD_2^2}{2}}}$\n\n$d = \\frac{\\text{Control Group Mean}-\\text{Experimental Group Mean}}{\\sqrt{\\text{Pooled Variance}}}$\n:::\n\n## Effect size\n\nIn psychology, we are often dealing with effect sizes that are small `(d = 0.3)`.\n\n-   A smaller effect size is harder to detect.\n\n## Alpha & beta & power\n\nWhen the effect size is small, the hypothetical alternative distribution is closer to the null distribution.\n\n![](images/clipboard-3726777508.png){width=\"313\"}\n\n## Effect size\n\nWhat can we do to increase power when an effect size is small?\n\n-   Take bigger samples (as per Central Limit Theorem)\n\n-   Design better experiments with more control and fewer confounds\n",
    "supporting": [
      "lec9_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}