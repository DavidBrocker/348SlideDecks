---
title: "Analysis of Variance"
subtitle: "Lecture 12"
author: "Dave Brocker"
footer: "PSY 348 - Statistics for Psychology"
institute: "Farmingdale State College"
format: 
  revealjs:
    theme: custom.scss
    scrollable: true
    width: 1600
    height: 900
    incremental: true   
    touch: true
    chalkboard: true
    lightbox: true
    code-fold: true
    drop:
      engine: webr
      webr:
        packages:
         - ggplot2
         - dplyr
revealjs-plugins:
  - drop
editor: 
  markdown: 
    wrap: 72
---

## Analysis of Variance

### ANOVA

ANOVA, like t-tests, compares the means of different groups to determine
if they differ significantly from one another.

-   ANOVA can examine independent variables with [**more than 2
    groups**]{.underline}.

-   ANOVA can also be used for just 2 groups.

-   It's more robust than t-tests.

## ANOVA

There are 3 types of ANOVA:

-   Between subjects

    -   Different participants are exposed to different levels of the iV

-   Within subjects (repeated measures ANOVA)

    -   The same participants are exposed to each level of the IV

-   Mixed designs (between and within together)

    -   Participants experience different levels of one IV and multiple
        levels of another IV

## Between subjects ANOVA

> The experimental group drinks caffeinated coffee. The placebo group
> drinks decaf. The control group drinks water. I ask all `3` groups to
> complete a survey to measure their happiness on a scale of `1` to
> `10`.

-   The experimental group has a mean happiness score `8`

-   The placebo group mean happiness score `6`

-   The control group mean happiness score `5`

    -   Is the group that drank coffee `significantly` happier than the
        other groups?

## Between subjects ANOVA

Is the variance between the green, red, and blue dots greater than the
variance across all of the dots?

```{r}
library(dplyr)
library(gt)
library(gtsummary)
library(ggplot2)
cof <- 
  tibble(
  condition = 
    rep(c("Coffee","Placebo","Control"), 
        each = 30),
  score = c(rnorm(30,7.5,1),
            rnorm(30,5,1),
            rnorm(30,5,2))
  ) 

cof |> 
  ggplot(aes(condition, score, color = condition)) + 
  geom_jitter(alpha = .25)  +
    stat_summary(
    fun.data = "mean_se",
    aes(group = 1),
    geom = "line",
    color = "black",
    show.legend = FALSE
  ) +
    stat_summary(
    fun.data = "mean_se",
    geom = "errorbar",
    width = .2
  ) + 
  theme_minimal(
    base_size = 20,
    paper = "ghostwhite",
    ink = "black") + 
  labs(
    x = "\nCondition",
    y = "Score\n"
  ) +
  theme_sub_panel(
    grid.major = element_blank()
  )
```

## Between subjects ANOVA

Is the variance between the green, red, and blue dots greater than the
variance across all of the dots?

```{r}
cof |> 
    tbl_summary(
      by = "condition",
      statistic = list(all_continuous() ~ c("{mean}({var}, {sd})"))
      ) |> 
  as_gt() |> 
  opt_row_striping() |> 
  tab_options(
    table.width = pct(50),
    table.font.size = 22
  )
```

## Between subjects ANOVA

-   If it's all about the means, why is it called Analysis of Variance?

## Between subjects ANOVA

-   To compare the means, we are analyzing two types of variance:

-   Variance among all of the scores *(within group variance)*

-   Variance *between the groups (between group variance).*

## The F Statistic

-   ANOVA produces what we call the F statistic.

-   Why do we call it F?

    -   Ronald Fischer â„¢

## Calculating F

-   $\large{F = \frac{MS_B}{MS_W} = \frac{\frac{SS_B}{df_b}}{\frac{SS_W}{df_B}}}$

-   $\large{SS_B = \sum_{j=1}^{k} n_j\big(\bar{y}{j} - \bar{y}{\cdot\cdot}\big)^2}$

-   $\large{SS_W = \sum_{j=1}^{k}\sum_{i=1}^{n_j}\big(y_{ij} - \bar{y}_{j}\big)^2}$

-   $\large{df_B = k-1}$

-   $\large{df_W = N - k}$

## Calculating F

### Calculating the variance

ANOVA looks at variance. To calculate the Variance:

-   Calculate the mean.

-   Subtract the mean from each x-value (deviation score).

-   Subtract the mean from each x-value (deviation score).

-   Square the deviation scores.

-   Take the sum of the squared deviations (Sum of Squared Deviations).

-   Divide by (n-1) - what is this called?

-   Divide by (degrees of freedom).

    -   **This is the variance**, but in ANOVA we also call it a Mean
        Squared (MS).

## Calculating means squared (SS)

-   Calculate the SS.

-   Divide the SS by the degrees of freedom.

## Calculating means squared (MS)

-   We will calculate a SS for the between group variance.

-   How much variance in the data is from group differences?

-   We will calculate a SS for all the data.

-   How much variance in the data is from random error?

## Between subjects ANOVA

-   SS~**BG**~ = How much variance comes comes from the group
    differences?

-   SS~**Error**~ = How much variance is there in total among all the
    data points?

## Calculating means squared (MS)

-   Calculate the SS~**BG**~.

-   Calculate the SS~**Error**~.

-   Divide the SS by their degrees of freedom.

## Degrees of freedom

The number of observations (data points) in the data that are free to
vary when estimating a statistic.

I own 7 hats. I want to wear a different hat every day of the week.

-   On Monday, I have 7 hats to choose from.

-   On Tuesday, I have 6 hats to choose from.

-   On Wednesday, I have 5 hats to choose from.

-   On Thursday, I have 4 hats to choose from.

-   On Friday, I have 3 hats to choose from.

-   On Saturday, I have 2 hats to choose from.

-   On Sunday, I don't get a choice. On Sunday, I have to wear the Santa
    hat.

-   The degrees of freedom is how many times I get a choice before I'm
    stuck with what's left over.

## Degrees of freedom

-   Between Groups (**MS~BG~** ) = k - 1

-   Within Groups (**MS~WG~**) = n - k

-   Total = n - 1

    -   k is the number of groups in the independent variable.

## Calculating means squared (MS)

-   Calculate the SS~**BG**~.

-   Calculate the SS~**Error**~.

-   Divide the SS by their degrees of freedom.

## Calculating the ms

-   Between Group Mean Squared: MS~**BG**~ = SS~**BG**~ / (k -- 1)

-   Error Mean Squared: **MS~Error~** = S**S~Error~** / (n -- k)

## Calculating Between subjects anova

**F = MS~BG~** / **MS~Error~**

## Calculating Between subjects anova

**F = MS~BG~** / **MS~Error~**

## Between subjects anova Example

> Prof Brocker gives one group of 100 participants the Super Secret
> Limitless Drug. He gives another group of 100 participants a placebo.
> He gives the third group of 100 participants nothing. All participants
> then complete an IQ test. She wants to know if those who took the SSLD
> has significantly higher IQ than the placebo and the control groups.

## Between subjects anova Example

## Between subjects anova Example

> Prof Brocker recruits 500 participants. He shows half of them the
> Netflix Original, Dark and the other half Jeopardy. HHe then measures
> their happiness on a scale of 1 to 10. He wants to know if Dark
> participants are significantly happier than the Jeopardy participants.

## Between subjects anova Example

## Interpreting f

## Interpreting f

The MS~BG~ is made up of the MS~Error~ + the theoretical difference
between groups:

-   MS~BG~ = *group difference* + **MS~Error~**

-   **MS~BG~ = *0* + MS~Error~**

-   **MS~BG~ = MS~Error~**

-   **F = MS~BG~ / MS~Error~**

-   **F = 1**

## Interpreting f

-   When F =\< 1, it's not likely to be significant.

## Interpreting f

The MS~BG~ is made up of the MS~Error~ + the theoretical difference
between groups:

-   MS~BG~ = *group difference* + **MS~Error~**

-   MS~BG~ = *NUMBER GREATER THAN 0* + **MS~Error~**

-   **F = DIFFERENCE + MS~Error~ / MS~Error~**

-   **F = DIFFERENCE**

## Hypothesis testing: ANOVA

-   F \< = 1 ---\> Fail to reject the Null Hypothesis

-   F \> 1 ---\> Refer to *p*-value ---\> Reject the Null Hypothesis

## Reporting f

## Reporting F

## If asked to report findings in terms of the Null Hypothesis (H0), you

should report findings as:

-   Reject H0, or

-   Fail to Reject H0

## Reporting F

If asked to report findings in general or for publication, you need to
report 5 things:

-   F(df for the between group MS, df for the error MS)

-   F-value

-   p-value

-   Mean and standard deviation of each group

## Reporting F

The group that watched Dark (M=8.43, s=1.02) reported significantly more
happiness compared to their peers in the control group who watched
Jeopardy (M=6.12, s=0.98), F(1,498) = 7.12, p \< 0.05.

## Reporting F

There was not a significant difference in happiness between the groups,
F (1, 498) = 1.02, p = 0.07.
